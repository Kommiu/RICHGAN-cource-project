{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T15:08:36.665076Z",
     "start_time": "2019-10-14T15:08:35.177235Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from importlib import reload\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import trange, tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import sys\n",
    "sys.path.insert(0, '/app')\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from lib.utils import plot_hist, score_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T15:08:36.697367Z",
     "start_time": "2019-10-14T15:08:36.667675Z"
    }
   },
   "outputs": [],
   "source": [
    "from models.model import Model\n",
    "import models.gans as gan\n",
    "import models.vae as vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T15:08:36.773853Z",
     "start_time": "2019-10-14T15:08:36.700767Z"
    }
   },
   "outputs": [],
   "source": [
    "seed = 52\n",
    "logdir = Path('/_data/richgan/runs')\n",
    "tag = 'cramer'\n",
    "# Вспомогательная функция, чтобы генерить одинаковые модели для каждой частицы\n",
    "def get_model():\n",
    "    latent_dim = 16\n",
    "    condition_dim = 3\n",
    "    target_dim = 5\n",
    "    d_hidden_dims = [64, 64, 128, 128]\n",
    "    g_hidden_dims = [64, 64, 128, 128]\n",
    "    output_dim = 128\n",
    "    \n",
    "\n",
    "    device = torch.device('cuda:0')\n",
    "    generator = gan.MLPGenerator(latent_dim, condition_dim, g_hidden_dims, target_dim,).to(device)\n",
    "    discriminator = gan.MLPDiscriminator(target_dim, condition_dim, d_hidden_dims, output_dim).to(device)\n",
    "\n",
    "    generator_opt = optim.Adam(generator.parameters(),  lr=1e-4, betas=(0, 0.9))\n",
    "    discriminator_opt = optim.Adam(discriminator.parameters(),  lr=1e-4, betas=(0, 0.9))\n",
    "\n",
    "    model = gan.CramerGAN(\n",
    "        generator,\n",
    "        discriminator,\n",
    "        generator_opt,\n",
    "        discriminator_opt,\n",
    "        lambda_gp=10,\n",
    "    )\n",
    "    \n",
    "    return Model(\n",
    "        model,\n",
    "        QuantileTransformer(output_distribution='normal', random_state=seed),\n",
    "        QuantileTransformer(output_distribution='normal', random_state=seed),\n",
    "        simulate_error_codes=True,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T15:08:44.212531Z",
     "start_time": "2019-10-14T15:08:36.775637Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e205c0e975e4079a2e3b637ca76c8c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_dir = Path('/_data/data_csv/')\n",
    "\n",
    "dataframes = {}\n",
    "for file in tqdm(data_dir.iterdir()):\n",
    "    name = file.stem.split('_')[1]\n",
    "    train, test = train_test_split(pd.read_csv(file.as_posix(), dtype=np.float32), random_state=seed)\n",
    "    dataframes[name]  =  {'train': train, 'test': test}\n",
    "    \n",
    "condition_cols = ['TrackP', 'TrackEta', 'NumLongTracks']\n",
    "target_cols = ['RichDLLbt', 'RichDLLk', 'RichDLLmu', 'RichDLLp', 'RichDLLe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-14T15:08:35.196Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e0aa33d6d174df89c540fbabc50e08c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db54209b4c6240a5bb3d16f90932cd26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=50), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e93a08dbce2418598a81b764f492537",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train', max=1444, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = dict()\n",
    "figs = defaultdict(dict)\n",
    "scores = dict()\n",
    "\n",
    "for particle in tqdm(['proton', 'muon', 'kaon', 'pion']):\n",
    "    \n",
    "    c_train = dataframes[particle]['train'][condition_cols]\n",
    "    x_train = dataframes[particle]['train'][target_cols]\n",
    "    c_test = dataframes[particle]['test'][condition_cols]\n",
    "    x_test = dataframes[particle]['test'][target_cols]\n",
    "    \n",
    "    model = get_model()\n",
    "    model.fit(\n",
    "        c_train,\n",
    "        x_train,\n",
    "        start_epoch=0,\n",
    "        num_epochs=50,\n",
    "        n_critic=1,\n",
    "        batch_size=512,\n",
    "        writer=SummaryWriter(log_dir=Path(logdir, tag, particle)),\n",
    "        num_workers=6,\n",
    "    )\n",
    "    models[particle] = model\n",
    "    predicted = model.predict(c_test)\n",
    "    reference = np.c_[x_test.values, c_test.values]\n",
    "    generated = np.c_[predicted.values, c_test.values]\n",
    "    score = score_func(generated, reference, n_slices=1000)\n",
    "    scores[particle] = score\n",
    "    print(particle, ': ', score)\n",
    "    for col in target_cols:\n",
    "        print(col)\n",
    "        fig = plot_hist(x_test[col].values, predicted[col].values)\n",
    "        figs[particle][col] = fig\n",
    "        display(fig)\n",
    "    print('='*100)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-14T15:08:35.202Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "figs_filtered = defaultdict(dict)\n",
    "scores_filtered = dict()\n",
    "for particle in tqdm(['proton', 'muon', 'kaon', 'pion']):\n",
    "    \n",
    "    c_test = dataframes[particle]['test'][condition_cols]\n",
    "    x_test = dataframes[particle]['test'][target_cols]\n",
    "    mask1 = (x_test == -999).values.all(axis=1)\n",
    "    mask2 = (x_test == 0).values.all(axis=1)\n",
    "    mask = (mask1 | mask2)\n",
    "    c_test = c_test[~mask]\n",
    "    x_test = x_test[~mask]\n",
    "    model = models[particle]\n",
    "    model.simulate_error_codes = False\n",
    "    predicted = model.predict(c_test)\n",
    "    reference = np.c_[x_test.values, c_test.values]\n",
    "    generated = np.c_[predicted.values, c_test.values]\n",
    "    score = score_func(generated, reference, n_slices=1000)\n",
    "    scores_filtered[particle] = score\n",
    "    print(particle, ': ', score)\n",
    "    for col in target_cols:\n",
    "        print(col)\n",
    "        fig = plot_hist(x_test[col].values, predicted[col].values)\n",
    "        figs_filtered[particle][col] = fig\n",
    "        display(fig)\n",
    "    print('='*100)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-14T15:08:35.206Z"
    }
   },
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-14T15:08:35.208Z"
    }
   },
   "outputs": [],
   "source": [
    "scores_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-14T15:08:35.212Z"
    }
   },
   "outputs": [],
   "source": [
    "for particle in figs:\n",
    "    for col in figs[particle]:\n",
    "        p = Path(f'/_data/richgan/pics/{tag}', particle)\n",
    "        p.mkdir(parents=True, exist_ok=True)\n",
    "        figs[particle][col].savefig(Path(p, col).with_suffix('.png').as_posix(), format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-14T15:08:35.216Z"
    }
   },
   "outputs": [],
   "source": [
    "for particle in figs_filtered:\n",
    "    for col in figs_filtered[particle]:\n",
    "        p = Path(f'/_data/richgan/pics/{tag}/', particle)\n",
    "        p.mkdir(parents=True, exist_ok=True)\n",
    "        figs_filtered[particle][col].savefig(Path(p, f'{col}-filtered').with_suffix('.png').as_posix(), format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
